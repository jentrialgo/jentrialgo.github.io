
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="./theme/stylesheet/style.min.css">


    <link id="pygments-light-theme" rel="stylesheet" type="text/css"
          href="./theme/pygments/github.min.css">



  <link rel="stylesheet" type="text/css" href="./theme/font-awesome/css/fontawesome.css">
  <link rel="stylesheet" type="text/css" href="./theme/font-awesome/css/brands.css">
  <link rel="stylesheet" type="text/css" href="./theme/font-awesome/css/solid.css">

  <link rel="stylesheet" type="text/css" href="./static/custom.css">



  <link href="https://jentrialgo.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Giving back to tech Atom">








        <link rel="canonical" href="./gpu-sharing.html">
 

<meta name="author" content="J.E." />
<meta name="description" content="I&#39;ve found this interesting post from 2022 by Nvidia about GPU sharing in Kubernetes. The main GPU sharing technologies can be summarized in this table: Technology Description MicroArchitecture CUDA Version CUDA Streams Allows concurrent operations within a single CUDA context using software abstraction. Pascal and later Not specified Time-Slicing Oversubscription strategy using the GPU&#39;s time-slicing scheduler. Pascal and later 11.1 (R455+ drivers) CUDA MPS MPS (Multi-Process Service) enables concurrent processing of CUDA kernels from different processes, typically MPI jobs. Not specified 11.4+ MIG MIG (Multi-Instance GPU) is a secure partitioning of GPUs into separate instances for dedicated resources. Ampere Architecture Not specified NVIDIA vGPU Provides VMs with simultaneous, direct access to a single physical GPU. Compatible with MIG-supported GPUs Not specified The post also explains how GPUs are advertised as schedulable resources in Kubernetes with the device plugin framework, but it is a integer-based resource, so it does not allow for oversuscription. They describe a way of achieving this with time-slicing APIs." />
<meta name="keywords" content="Nvidia, GPU, Kubernetes">


  <meta property="og:site_name" content="Giving back to tech"/>
  <meta property="og:title" content="GPU sharing"/>
  <meta property="og:description" content="I&#39;ve found this interesting post from 2022 by Nvidia about GPU sharing in Kubernetes. The main GPU sharing technologies can be summarized in this table: Technology Description MicroArchitecture CUDA Version CUDA Streams Allows concurrent operations within a single CUDA context using software abstraction. Pascal and later Not specified Time-Slicing Oversubscription strategy using the GPU&#39;s time-slicing scheduler. Pascal and later 11.1 (R455+ drivers) CUDA MPS MPS (Multi-Process Service) enables concurrent processing of CUDA kernels from different processes, typically MPI jobs. Not specified 11.4+ MIG MIG (Multi-Instance GPU) is a secure partitioning of GPUs into separate instances for dedicated resources. Ampere Architecture Not specified NVIDIA vGPU Provides VMs with simultaneous, direct access to a single physical GPU. Compatible with MIG-supported GPUs Not specified The post also explains how GPUs are advertised as schedulable resources in Kubernetes with the device plugin framework, but it is a integer-based resource, so it does not allow for oversuscription. They describe a way of achieving this with time-slicing APIs."/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="./gpu-sharing.html"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2024-04-05 10:00:00+02:00"/>
  <meta property="article:modified_time" content=""/>
  <meta property="article:author" content="./author/je.html">
  <meta property="article:section" content="Nvidia, GPU, Kubernetes"/>
  <meta property="article:tag" content="Nvidia"/>
  <meta property="article:tag" content="GPU"/>
  <meta property="article:tag" content="Kubernetes"/>
  <meta property="og:image" content="images/profile.jpg">

  <title>Giving back to tech &ndash; GPU sharing</title>


</head>
<body class="light-theme">

<aside>
  <div>
    <a href="./">
      <img src="images/profile.jpg" alt="Giving back to tech" title="Giving back to tech">
    </a>

    <h1>
      <a href="./">Giving back to tech</a>
    </h1>



    <nav>
      <ul class="list">



          <li>
            <a target="_self" href="https://jentrialgo.github.io/personal-website/" >Personal page</a>
          </li>
          <li>
            <a target="_self" href="https://github.com/jentrialgo" >GitHub page</a>
          </li>
          <li>
            <a target="_self" href="/archives.html" >All posts</a>
          </li>
      </ul>
    </nav>

    <ul class="social">
      <li>
        <a class="sc-Linked.in"
           href="https://www.linkedin.com/in/joaqu%C3%ADn-entrialgo-casta%C3%B1o-8a74714b/"
           target="_blank">
          <i class="fa-brands fa-Linked.in"></i>
        </a>
      </li>
    </ul>
  </div>

</aside>
  <main>

<nav>
  <a href="./">Home</a>

  <a href="./pages/about.html#about">About</a>
  <a href="/tags.html">Tags</a>

  <a href="https://jentrialgo.github.io/feeds/all.atom.xml">Atom</a>

</nav>

<article class="single">
  <header>
      
    <h1 id="gpu-sharing">GPU sharing</h1>
    <p>
      Posted on Fri 05 April 2024 in <a href="./category/nvidia-gpu-kubernetes.html">Nvidia, GPU, Kubernetes</a>

    </p>
  </header>


  <div>
    <p>I've found this <a href="https://developer.nvidia.com/blog/improving-gpu-utilization-in-kubernetes/">interesting post from 2022 by Nvidia about GPU sharing in
Kubernetes</a>.</p>
<p>The main GPU sharing technologies can be summarized in this table:</p>
<table>
<thead>
<tr>
<th>Technology</th>
<th>Description</th>
<th>MicroArchitecture</th>
<th>CUDA Version</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CUDA Streams</strong></td>
<td>Allows concurrent operations within a single CUDA context using software abstraction.</td>
<td>Pascal and later</td>
<td>Not specified</td>
</tr>
<tr>
<td><strong>Time-Slicing</strong></td>
<td>Oversubscription strategy using the GPU's time-slicing scheduler.</td>
<td>Pascal and later</td>
<td>11.1 (R455+ drivers)</td>
</tr>
<tr>
<td><strong>CUDA MPS</strong></td>
<td>MPS (Multi-Process Service) enables concurrent processing of CUDA kernels from different processes, typically MPI jobs.</td>
<td>Not specified</td>
<td>11.4+</td>
</tr>
<tr>
<td><strong>MIG</strong></td>
<td>MIG (Multi-Instance GPU) is a secure partitioning of GPUs into separate instances for dedicated resources.</td>
<td>Ampere Architecture</td>
<td>Not specified</td>
</tr>
<tr>
<td><strong>NVIDIA vGPU</strong></td>
<td>Provides VMs with simultaneous, direct access to a single physical GPU.</td>
<td>Compatible with MIG-supported GPUs</td>
<td>Not specified</td>
</tr>
</tbody>
</table>
<p>The post also explains how GPUs are advertised as schedulable resources in Kubernetes with
the device plugin framework, but it is a integer-based resource, so it does not allow for
oversuscription. They describe a way of achieving this with time-slicing APIs.</p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="./tag/nvidia.html">Nvidia</a>
      <a href="./tag/gpu.html">GPU</a>
      <a href="./tag/kubernetes.html">Kubernetes</a>
    </p>
  </div>







</article>

<footer>
<p>&copy;  </p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p></footer>  </main>

<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Giving back to tech ",
  "url" : ".",
  "image": "images/profile.jpg",
  "description": ""
}
</script>
</body>
</html>